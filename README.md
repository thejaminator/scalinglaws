## Install
```
pip install -r requirements.txt
```
## To generate data for evaluation
```bash
python main.py
```
The data will be saved in the `data` folder.

# Stages
The pipeline stages are described [here](https://wooden-supply-593.notion.site/SERIMATS-task-Ethan-Perez-s-stream-531b41ad46ef400da517a3458311e174)
## Stage One
[lm_agree_statements.jsonl](data%2Flm_agree_statements.jsonl)
lm_agree_statements.jsonl: The raw "sad but true" statements generated by the language model

[lm_disagree_statements.jsonl](data%2Flm_disagree_statements.jsonl)
lm_disagree_statements.jsonl: The raw "nice but false" statements generated by the language model

## Stage Two
[preference_agree_cot.jsonl](data%2Fpreference_agree_cot.jsonl)
preference_agree_cot.jsonl: The "sad but true" statements evaluated by the preference model

[preference_disagree_cot.jsonl](data%2Fpreference_disagree_cot.jsonl)
preference_disagree_cot.jsonl: The "nice but false" statements evaluated by the preference model

## Stage Three

You may view the data generated for such prompt format.
For example, to view the `FewShot` data, navigate to [data/FewShotTrue](data/FewShotTrue) folder.

[statements_filtered.csv](data%2FFewShotTrue%2Fstatements_filtered.csv)
statements_filtered.csv: The statements used for the evaluation.

![vanilla_and_feedme.png](data%2FFewShotTrue%2Fvanilla_and_feedme.png)
vanilla_and_feedme.png: The vanilla GPT-3 and FeedMe models accuracy

![vanilla_and_feedme_yes.png](data%2FFewShotTrue%2Fvanilla_and_feedme_yes.png)
vanilla_and_feedme_yes.png: The vanilla GPT-3 and FeedMe models accuracy on "sad but true" statements.

![vanilla_and_feedme_no.png](data%2FFewShotTrue%2Fvanilla_and_feedme_no.png)
vanilla_and_feedme_no.png: The vanilla GPT-3 and FeedMe models accuracy on "nice but false" statements.

